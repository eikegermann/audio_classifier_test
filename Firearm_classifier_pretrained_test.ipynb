{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_fehbZHoSBImUu3kziksqpMeZGHzyBSU",
      "authorship_tag": "ABX9TyP2dfzgKUU/L513POwLMEuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eikegermann/audio_classifier_test/blob/main/Firearm_classifier_pretrained_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyroomacoustics"
      ],
      "metadata": {
        "id": "Dl5mysPHRhEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import torch\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pyroomacoustics as pra\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "WJwIlA3WusFq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RhPuFsf0uKJh"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, root_dir, augment=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.labels = sorted(os.listdir(self.root_dir))\n",
        "        self.filepaths = list(Path(root_dir).rglob(\"*.wav\"))\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filepaths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        audio_file_path = self.filepaths[index]\n",
        "        label = self.labels.index(Path(audio_file_path).parent.name)\n",
        "\n",
        "        audio, sr = librosa.load(audio_file_path, sr=16000)  # Load audio at 16kHz sample rate\n",
        "\n",
        "        if self.augment:\n",
        "            audio = self.apply_augmentation(audio, sr)\n",
        "\n",
        "        # Pad or trim audio to a fixed length of 0.96 seconds (15360 samples)\n",
        "        max_length = 15360\n",
        "        audio_padded = np.zeros(max_length)\n",
        "        audio_padded[:min(max_length, len(audio))] = audio[:max_length]\n",
        "\n",
        "        # Compute mel-spectrogram\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(audio_padded, sr=sr, n_fft=400, hop_length=160, n_mels=64)\n",
        "        mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "        audio_tensor = torch.tensor(mel_spectrogram).float()\n",
        "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return audio_tensor.unsqueeze(0), label_tensor\n",
        "\n",
        "    def add_reverb(audio, sr=16000, max_order=10, absorption=0.5):\n",
        "        # Create a shoebox room with the given dimensions and absorption\n",
        "        room_dim = np.array([10, 7, 3])\n",
        "        room = pra.ShoeBox(room_dim, absorption=absorption, fs=sr, max_order=max_order)\n",
        "\n",
        "        # Place the source and microphone in the room\n",
        "        room.add_source([2, 3, 2], signal=audio)\n",
        "        room.add_microphone_array(pra.MicrophoneArray(np.array([[4, 5, 2]]).T, room.fs))\n",
        "\n",
        "        # Compute the RIR (room impulse response)\n",
        "        room.compute_rir()\n",
        "\n",
        "        # Simulate the reverberant audio\n",
        "        room.simulate()\n",
        "        reverberant_audio = room.mic_array.signals[0, :]\n",
        "\n",
        "        # Normalize the audio to avoid clipping or distortion\n",
        "        reverberant_audio = reverberant_audio / np.max(np.abs(reverberant_audio))\n",
        "\n",
        "        return reverberant_audio\n",
        "\n",
        "    def apply_frequency_mask(audio, sr, mask_factor=0.5):\n",
        "        # Convert audio to the frequency domain using the short-time Fourier transform (STFT)\n",
        "        stft = librosa.stft(audio)\n",
        "\n",
        "        # Generate a random frequency mask\n",
        "        mask_shape = stft.shape\n",
        "        mask = np.random.uniform(low=1-mask_factor, high=1, size=mask_shape)\n",
        "\n",
        "        # Apply the mask to the STFT\n",
        "        masked_stft = np.multiply(stft, mask)\n",
        "\n",
        "        # Convert the masked STFT back to the time domain\n",
        "        masked_audio = librosa.istft(masked_stft)\n",
        "\n",
        "        return masked_audio        \n",
        "\n",
        "\n",
        "    def apply_augmentation(self, audio, sr):\n",
        "        num_augmentations = random.choice([0, 1, 2])\n",
        "\n",
        "        augmentation_types = ['pitch_shift', 'add_noise', 'time_stretch', 'reverb', 'masking']\n",
        "        random.shuffle(augmentation_types)\n",
        "\n",
        "        for i in range(num_augmentations):\n",
        "            augmentation_type = augmentation_types[i]\n",
        "\n",
        "            if augmentation_type == 'pitch_shift':\n",
        "                pitch_shift = round(random.uniform(-2, 2), 2)\n",
        "                audio = librosa.effects.pitch_shift(audio, sr, pitch_shift)\n",
        "            \n",
        "            elif augmentation_type == 'add_noise':\n",
        "                noise = np.random.normal(0, 0.005, len(audio))\n",
        "                audio = audio + noise\n",
        "                \n",
        "            elif augmentation_type == 'time_stretch':\n",
        "                rate = random.uniform(0.9, 1.1)\n",
        "                audio = librosa.effects.time_stretch(audio, rate)\n",
        "            \n",
        "            elif augmentation_type == 'reverb':\n",
        "                audio = add_reverb(audio, sr)\n",
        "\n",
        "            elif augmentation_type == 'masking':\n",
        "                audio = apply_frequency_mask(audio, sr)\n",
        "\n",
        "        return audio\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwjqN74lvCrF",
        "outputId": "5f51a480-5398-41f9-f3ea-8dd672c6733a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"drive/MyDrive/audio_ml_data/firearm_samples/\"\n",
        "train_dataset = AudioDataset(data_path + \"train/\")\n",
        "test_dataset = AudioDataset(data_path + \"test/\")"
      ],
      "metadata": {
        "id": "TwJQQSQru8vO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CustomVGGishClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(CustomVGGishClassifier, self).__init__()\n",
        "        self.vggish = torch.hub.load('harritaylor/torchvggish', 'vggish', preprocess=False)\n",
        "        self.fc = nn.Linear(128, num_classes)  # 128 is the output size of VGGish\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vggish(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jOcEcYO5v6yw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the custom VGGish model and send it to the device\n",
        "model = CustomVGGishClassifier(num_classes=3)\n",
        "model.to(device)\n",
        "\n",
        "# Initialize the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Set up the data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "best_f1 = 0.0\n",
        "best_checkpoint = None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    train_preds, train_labels = [], []\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "        train_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    # Print the average loss for this epoch\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    \n",
        "    # Calculate train accuracy and F1 score\n",
        "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "    train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "\n",
        "    # Evaluate on test data\n",
        "    model.eval()\n",
        "    test_preds, test_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            test_preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
        "            test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "    test_f1 = f1_score(test_labels, test_preds, average='macro')\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Acc: {train_accuracy:.4f}, Train F1: {train_f1:.4f}, Test Acc: {test_accuracy:.4f}, Test F1: {test_f1:.4f}\")\n",
        "\n",
        "    # Save the best checkpoint based on the test F1 score\n",
        "    if test_f1 > best_f1:\n",
        "        best_f1 = test_f1\n",
        "        best_checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': epoch_loss,\n",
        "            'train_accuracy': train_accuracy,\n",
        "            'train_f1': train_f1,\n",
        "            'test_accuracy': test_accuracy,\n",
        "            'test_f1': test_f1\n",
        "        }\n",
        "        torch.save(best_checkpoint, 'best_checkpoint.pth')\n",
        "\n",
        "print(\"Finished Training\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkRX2t90xKc9",
        "outputId": "364c504f-ba29-43d1-e058-8dc93aa907bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/harritaylor_torchvggish_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 75.4350, Train Acc: 0.3750, Train F1: 0.1846, Test Acc: 0.3143, Test F1: 0.1977\n",
            "Epoch [2/20], Loss: 49.3735, Train Acc: 0.3542, Train F1: 0.2387, Test Acc: 0.2857, Test F1: 0.2527\n",
            "Epoch [3/20], Loss: 30.3287, Train Acc: 0.3333, Train F1: 0.2489, Test Acc: 0.4000, Test F1: 0.3202\n",
            "Epoch [4/20], Loss: 25.8293, Train Acc: 0.3333, Train F1: 0.2699, Test Acc: 0.4286, Test F1: 0.3348\n",
            "Epoch [5/20], Loss: 28.2136, Train Acc: 0.3125, Train F1: 0.2355, Test Acc: 0.5143, Test F1: 0.3928\n",
            "Epoch [6/20], Loss: 22.6187, Train Acc: 0.5208, Train F1: 0.3728, Test Acc: 0.6000, Test F1: 0.4294\n",
            "Epoch [7/20], Loss: 19.3827, Train Acc: 0.6458, Train F1: 0.5143, Test Acc: 0.5429, Test F1: 0.4528\n",
            "Epoch [8/20], Loss: 17.7788, Train Acc: 0.5000, Train F1: 0.4211, Test Acc: 0.6000, Test F1: 0.5206\n",
            "Epoch [9/20], Loss: 16.2748, Train Acc: 0.5208, Train F1: 0.4030, Test Acc: 0.5429, Test F1: 0.4553\n",
            "Epoch [10/20], Loss: 13.1785, Train Acc: 0.5625, Train F1: 0.4885, Test Acc: 0.6000, Test F1: 0.4998\n",
            "Epoch [11/20], Loss: 12.1342, Train Acc: 0.6042, Train F1: 0.5108, Test Acc: 0.5714, Test F1: 0.4506\n",
            "Epoch [12/20], Loss: 12.6338, Train Acc: 0.5208, Train F1: 0.4585, Test Acc: 0.4857, Test F1: 0.3937\n",
            "Epoch [13/20], Loss: 10.5824, Train Acc: 0.5000, Train F1: 0.4610, Test Acc: 0.6000, Test F1: 0.5472\n",
            "Epoch [14/20], Loss: 9.4833, Train Acc: 0.6667, Train F1: 0.5905, Test Acc: 0.5143, Test F1: 0.4411\n",
            "Epoch [15/20], Loss: 9.6129, Train Acc: 0.6458, Train F1: 0.5616, Test Acc: 0.5429, Test F1: 0.4036\n",
            "Epoch [16/20], Loss: 8.6089, Train Acc: 0.6875, Train F1: 0.6111, Test Acc: 0.6571, Test F1: 0.5413\n",
            "Epoch [17/20], Loss: 7.0387, Train Acc: 0.6042, Train F1: 0.5071, Test Acc: 0.5714, Test F1: 0.5372\n",
            "Epoch [18/20], Loss: 6.6955, Train Acc: 0.6042, Train F1: 0.5655, Test Acc: 0.5143, Test F1: 0.4793\n",
            "Epoch [19/20], Loss: 5.7713, Train Acc: 0.5833, Train F1: 0.5399, Test Acc: 0.6286, Test F1: 0.5682\n",
            "Epoch [20/20], Loss: 5.4976, Train Acc: 0.6667, Train F1: 0.5778, Test Acc: 0.6571, Test F1: 0.5413\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZS2TdLcFzT5i"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}